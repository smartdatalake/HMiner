// export nodes
CALL apoc.export.csv.query("MATCH (a:Author) WHERE a.id < 100000 RETURN distinct(a.id), a.name", "/tmp/A_100k.csv", {})
CALL apoc.export.csv.query("MATCH (a:Author)-->(p:Paper) WHERE a.id < 100000 RETURN distinct(p.aminer_id), p.title, p.year", "/tmp/P_100k.csv", {})
CALL apoc.export.csv.query("MATCH (a:Author)-->(p:Paper)-->(v:Venue) WHERE a.id < 100000 RETURN distinct(v.id), v.name", "/tmp/C_100k.csv", {})

// export relations
CALL apoc.export.csv.query("MATCH (a:Author)-->(p:Paper) WHERE a.id < 100000 RETURN a.id, p.aminer_id", "/tmp/AP_100k.csv", {})
CALL apoc.export.csv.query("MATCH (a:Author)-->(p:Paper)-->(v:Venue) WHERE a.id < 100000 RETURN p.aminer_id, v.id", "/tmp/PC_100k.csv", {})

// remove quotes & add tab
cat A_100k.csv | awk -F',' '{gsub(/"/, "", $1);gsub(/"/, "", $2);print $1"\t"$2}' > A.csv
cat C_100k.csv | awk -F',' '{gsub(/"/, "", $1);gsub(/"/, "", $2);print $1"\t"$2}' > C.csv
cat P_100k.csv | awk -F',' '{gsub(/"/, "", $1);gsub(/"/, "", $2);gsub(/"/, "", $3);print $1"\t"$2"\t"$3}' > P.csv
cat AP_100k.csv | awk -F',' '{gsub(/"/, "", $1);gsub(/"/, "", $2);print $1"\t"$2}' > AP.csv
cat PC_100k.csv | awk -F',' '{gsub(/"/, "", $1);gsub(/"/, "", $2);print $1"\t"$2}' > PC.csv

- remove header from P.csv
- cat P.csv | awk -F'\t' '{print NR-1"\t"$0}' > P2.csv
- mv P2.csv P.csv
- add head to P.csv again
- remove headers from relation files
- configure assign_ids.py to produce AP.csv and PC.csv 
- remove duplicates
	cat AP.csv | sort | uniq > AP_final.csv
	cat PC.csv | sort | uniq > PC_final.csv
- sort numeric based on first column
	sort -k1 -n -o AP.csv AP.csv
	sort -k1 -n -o PC.csv PC.csv
    mv PC.csv PC.crs
    mv AP.csv AP.crs

- sort numeric based on second column
    sort -k2 -n -o AP.csv AP.ccs
    sort -k2 -n -o PC.csv PC.ccs

- create inverted crs and ccs files
    cat AP.crs | awk -F'\t' '{print $2"\t"$1}' > PA.ccs
    cat PC.crs | awk -F'\t' '{print $2"\t"$1}' > CP.ccs
    sort -k1 -n CP.ccs > CP.crs
    sort -k1 -n PA.ccs > PA.crs

